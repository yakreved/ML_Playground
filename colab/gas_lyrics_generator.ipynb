{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILxfzLKBA5xI"
   },
   "source": [
    "Сделано на основе https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aHK2CYygXom"
   },
   "source": [
    "## Import TensorFlow and related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2LmLTREBf5ng"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Other imports for processing data\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "397LUEtGzazw"
   },
   "source": [
    "Может обучить сначала на куче текстов, а потом трансформнуть для сектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxDIPSDpzkD6",
    "outputId": "fb3e7b01-0cba-4dcf-f72e-019923ff31a2"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/d0rj/RusLit/archive/refs/heads/main.zip --output-document ./literature.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuELN1cj0EbJ"
   },
   "outputs": [],
   "source": [
    "!unzip literature.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aaIPlQXJ6iyG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197418\n",
      "['Александр Блок  endline\\nВОЗМЕЗДИЕ  endline\\n Юность - это возмездие.  endline\\n Ибсен  endline\\nПРЕДИСЛОВИЕ  endline\\n  endline\\n ', ' Не чувствуя ни нужды, ни охоты заканчивать поэму, полную революционных  endline\\nпредчувствий, в года, когда революция уже произошла, я хочу предпослать  endline\\nнаброску последней главы рассказ о том, как п', 'оэма родилась, каковы были  endline\\nпричины ее возникновения, откуда произошли ее ритмы.  endline\\n Интересно и небесполезно и для себя, и для других припомнить историю  endline\\nсобственного произведения. К тому же нам,', ' счастливейшим или несчастливейшим  endline\\nдетям своего века, приходится помнить всю свою жизнь; все годы наши резко  endline\\nокрашены для нас, и - увы! - забыть их нельзя, - они окрашены слишком  endline\\nнеизгладимо', ', так что каждая цифра кажется написанной кровью; мы и не можем  endline\\nзабыть этих цифр; они написаны на наших собственных лицах.  endline\\n  endline\\n Поэма \"Возмездие\" была задумана в 1910 году и в главных чер', 'тах была  endline\\nнабросана в 1911 году. Что это были за годы?  endline\\n 1910 год - это смерть Коммиссаржевской, смерть Врубеля и смерть  endline\\nТолстого. С Коммиссаржевской умерла лирическая нота на сцене; с Вр', 'убелем -  endline\\nгромадный личный мир художника, безумное упорство, ненасытность исканий -  endline\\nвплоть до помешательства. С Толстым умерла человеческая нежность - мудрая  endline\\nчеловечность.  endline\\n Далее, 1910 год', ' - это кризис символизма, о котором тогда очень много  endline\\nписали и говорили, как в лагере символистов, так и в противоположном. В  endline\\nэтом году явственно дали о себе знать направления, которые в', 'стали во  endline\\nвраждебную позицию и к символизму, и друг к другу: акмеизм, эгофутуризм и  endline\\nпервые начатки футуризма. Лозунгом первого из этих направлений был человек  endline\\n- но какой-то уже другой челове', 'к, вовсе без человечности, какой-то  endline\\n\"первозданный\" Адам.  endline\\n Зима 1911 года была исполнена глубокого внутреннего мужественного  endline\\nнапряжения и трепета. Я помню ночные разговоры, из к']\n"
     ]
    }
   ],
   "source": [
    "from get_literature_dadaset import get_literature_dataset\n",
    "dataset = get_literature_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIWhZ4uwAjLr"
   },
   "source": [
    "Нет! Мы нафигачим сюда текстов Сектора газа!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "unzJsmM4Aoke",
    "outputId": "2f330ad5-8be9-4055-a09d-84c0d1504f5a"
   },
   "outputs": [],
   "source": [
    "from get_sector_songs import get_sector_songs\n",
    "dataset_2 = get_sector_songs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWbMN_19jfRT"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRmPPJegovBe",
    "outputId": "429e6a69-ca61-4c7f-a4aa-f86de85a519e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "(181900, 246)\n",
      "(1931, 246)\n"
     ]
    }
   ],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "def create_lyrics_corpus(dataset, field):\n",
    "  # Remove all other punctuation\n",
    "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "  # Make it lowercase\n",
    "  dataset[field] = dataset[field].str.lower()\n",
    "  # Make it one long string to split by line\n",
    "  lyrics = dataset[field].str.cat()\n",
    "  corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "  for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "  corpus = [l for l in corpus if l != '']\n",
    "\n",
    "  return corpus\n",
    "\n",
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "# Read the dataset from csv - this time with 250 songs\n",
    "#dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
    "# Create the corpus using the 'text' column containing lyrics\n",
    "def create_imput_data(corpus, max_sequence_len=None):\n",
    "  sequences = []\n",
    "  for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "      n_gram_sequence = token_list[:i+1]\n",
    "      sequences.append(n_gram_sequence)\n",
    "\n",
    "  # Pad sequences for equal input length \n",
    "  if max_sequence_len is None:\n",
    "    max_sequence_len = max([len(seq) for seq in sequences])\n",
    "  sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "  # Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "  input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "  # One-hot encode the labels\n",
    "  one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "  return max_sequence_len, input_sequences, one_hot_labels\n",
    "\n",
    "corpus = create_lyrics_corpus(dataset, 'text')\n",
    "# Tokenize the corpus\n",
    "tokenizer = tokenize_corpus(corpus, num_words=3000)\n",
    "total_words = tokenizer.num_words\n",
    "\n",
    "# There should be a lot more words now\n",
    "print(total_words)\n",
    "\n",
    "max_sequence_len, input_sequences, one_hot_labels = create_imput_data(corpus)\n",
    "_, input_sequences_2, one_hot_labels_2 = create_imput_data(create_lyrics_corpus(dataset_2, 'text'), max_sequence_len)\n",
    "print(input_sequences.shape)\n",
    "print(input_sequences_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cECbqT-blMk-"
   },
   "source": [
    "### Train a (Better) Text Generation Model\n",
    "\n",
    "Сначала Корпус русской классики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nHOp6uWlP_P",
    "outputId": "d0884ff6-594b-4c4e-8cb6-bc915af1bd9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 246, 16)           48000     \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 246, 128)         41472     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3000)              195000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 325,688\n",
      "Trainable params: 325,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      " 680/5685 [==>...........................] - ETA: 11:31 - loss: 5.5093 - accuracy: 0.3053"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, AdditiveAttention\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 16, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdmK85snLUdb"
   },
   "source": [
    "## Трансфер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13aNar5bLani",
    "outputId": "9c1da794-9d0d-4c33-e792-29118f855eb3"
   },
   "outputs": [],
   "source": [
    "model.save('fitsrt_step_model') # saves compiled state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwgytLtuMqlt",
    "outputId": "a6c7a094-35ed-4b42-ab10-5f6b838277eb"
   },
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('fitsrt_step_model')\n",
    "history2 = model2.fit(input_sequences_2, one_hot_labels_2, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgvIz20nlQcq"
   },
   "source": [
    "### View the Training Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "rOqmmarvlSLh",
    "outputId": "ac83ca17-4281-48a1-b812-e6edf4cbb81d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upgJKV8_oRU9"
   },
   "source": [
    "### Varying the Possible Outputs\n",
    "\n",
    "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
    "\n",
    "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee7WKgRGrJy1",
    "outputId": "e9af5ec8-7ffc-4a12-b022-f02347e71e51"
   },
   "outputs": [],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"Грустный клоун\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "  predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "seed_text = seed_text.replace('endline', '\\n')\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlHj-HArUNuf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEEkXg6pUOVl",
    "outputId": "55922831-85f6-4248-cf7c-d24d16ff9b07"
   },
   "outputs": [],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"Грустный клоун\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "  predicted_probs = model2.predict(token_list, verbose=0)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "seed_text = seed_text.replace('endline', '\\n')\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
